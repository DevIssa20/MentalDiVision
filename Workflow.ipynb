{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this notebook, we'll go through the steps of creating a fun computer vision math game using mediapipe, opencv, and sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll import some important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #For working with numpy arrays and functions\n",
    "import cv2 #For working with images\n",
    "import mediapipe as mp #For hand tracking\n",
    "import time #For timing\n",
    "import random #For generating random numbers\n",
    "from sklearn.linear_model import LogisticRegression #For training a more advanced countingFingers version\n",
    "import pandas as pd #For loading and working with csv files\n",
    "import pickle\n",
    "\n",
    "#If you don't have these libraries installed, run \"pip install -r requirements.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll import our HandDetector class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import HandtrackingModule as htm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the function to count the number of fingers raised. The function increments fingersRaised if the tip landmark for each finger is higher than the landmarks below it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countFingersRaised(lmList): #Takes landmarks list and outputs the number of fingers raised\n",
    "    tipIds = [4, 8, 12, 16, 20] #Tips of : [Thumb, Index, Middle, Ring, Pinky] \n",
    "    fingersRaised = 0\n",
    "    if(len(lmList) > 0):\n",
    "        for hand in range(len(lmList)):\n",
    "            for tip in tipIds:\n",
    "                if(tip == 4): #Thumb raises along both x and y axis so it has some special logic\n",
    "                    if(lmList[hand][4][1] < lmList[hand][0][1]):\n",
    "                        if(lmList[hand][4][1] < lmList[hand][3][1]):\n",
    "                            fingersRaised += 1\n",
    "                    \n",
    "                    elif(lmList[hand][4][1] > lmList[hand][0][1]):\n",
    "                        if(lmList[hand][4][1] > lmList[hand][3][1]):\n",
    "                            fingersRaised += 1\n",
    "                            \n",
    "                elif(lmList[hand][tip][2] < lmList[hand][tip-2][2]): #Rest of Fingers\n",
    "                    fingersRaised += 1\n",
    "            \n",
    "    return fingersRaised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll define a function to start capturing frames from the camera and show us the image as well as the number of fingers raised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def captureAndDetect(countFingersRaised): #Captures camera footage using cv2 and shows the image after processing it\n",
    "    pTime = 0\n",
    "    cTime = 0\n",
    "    cap = cv2.VideoCapture(0) #Create video object\n",
    "    detector = htm.HandDetector() #Initialize hand detector\n",
    "    try:\n",
    "        while True: #Start camera footage\n",
    "            success, img = cap.read()\n",
    "            img = cv2.flip(img, 1)\n",
    "            lmList, img = detector.findLandmarks(img)\n",
    "            fingersRaised = countFingersRaised(lmList)\n",
    "            \n",
    "            #Calculate frames per second\n",
    "            cTime = time.time()\n",
    "            fps = 1/(cTime - pTime)\n",
    "            pTime = cTime\n",
    "            \n",
    "            cv2.putText(img, str(int(fps)), (10,70), cv2.FONT_HERSHEY_PLAIN, 3,(255,0,255),3) #display fps\n",
    "            cv2.putText(img, str(fingersRaised), (560,70), cv2.FONT_HERSHEY_PLAIN, 4,(255,0,255),4) #display fingers raised\n",
    "            \n",
    "            cv2.imshow(\"Image\", img)\n",
    "            cv2.waitKey(1)\n",
    "    except KeyboardInterrupt:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()  # Close all OpenCV windows\n",
    "        cap = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try calling the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "captureAndDetect(countFingersRaised) #Interrupt whenever you want"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm seems to be working well ! It detects the fingrs raised with great accuracy, as long as the you raise your fingers with your palms straight and facing forwards. We'll revisit the countingFingersRaised() function to make it work more accurately and in more cases later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's work on our maths game !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computerVisionMath(countFingersRaised, numQuestions):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    detector = htm.HandDetector()\n",
    "    newRound = True\n",
    "    rand1 = rand2 = res = 0\n",
    "    framesRight = 0\n",
    "    prevRand2 = 0\n",
    "    round = 0\n",
    "    \n",
    "    try:\n",
    "        while round <= numQuestions:\n",
    "            success, img = cap.read()\n",
    "            img = cv2.flip(img, 1)\n",
    "            \n",
    "            lmList, img = detector.findLandmarks(img)\n",
    "            fingersRaised = countFingersRaised(lmList)\n",
    "            \n",
    "            if newRound:\n",
    "                round += 1\n",
    "                if(round > numQuestions):\n",
    "                    continue\n",
    "                rand1 = random.randint(1,10)\n",
    "                while(rand2 == prevRand2):\n",
    "                    rand2 = random.randint(1,10)\n",
    "                prevRand2 = rand2\n",
    "                res = rand1 * rand2\n",
    "                print(f\"Question {round}/{numQuestions} : {res} / {rand1} = \", end = \"\")\n",
    "                newRound = False\n",
    "            \n",
    "            if(fingersRaised == rand2):\n",
    "                framesRight += 1\n",
    "                if(framesRight == 3): #You should get 3 frames right continously -> Avoid accidental answers\n",
    "                    print(fingersRaised)\n",
    "                    newRound = True\n",
    "                    framesRight = 0\n",
    "            else:\n",
    "                framesRight = 0\n",
    "            \n",
    "            cv2.imshow(\"Computer Vision Math\", img)\n",
    "            cv2.waitKey(1)\n",
    "        cap.release() #Release camera\n",
    "        cv2.destroyAllWindows()  # Close all OpenCV windows\n",
    "        cap = None\n",
    "    except KeyboardInterrupt:\n",
    "        cap.release() #Release camera\n",
    "        cv2.destroyAllWindows()  # Close all OpenCV windows\n",
    "        cap = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try out our math game !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1/3 : 24 / 6 = 4\n",
      "Question 2/3 : 30 / 3 = 10\n",
      "Question 3/3 : 35 / 5 = 7\n"
     ]
    }
   ],
   "source": [
    "computerVisionMath(countFingersRaised, 3) #First argument is the function we wanna use to count the fingers, second argument is for how many math questions do you want to solve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works out amazingly well ! With that, we now have a fun computer vision math game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extras : Implementing a more advanced countingFingersRaised algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our countingFingersRaised function works well if the player keeps their palms up straight and facing forward, but we can do better !\n",
    "Instead of detecting raised fingers based on the x and y positions of the landmarks, we can use a more powerful relation : The angle between the two vectors of every three landmarks.\n",
    "\n",
    "Explanation :\n",
    "When raising your finger, the if we vector lines between the landmarks representing the joints of your fingers, we'll notice that the angles formed between the intersecting vectors are pretty obtuse (close to 180 degrees). Alternatively, when your fingers are closed, the angles formed between the intersecting vectors are relatively low in comparison.\n",
    "\n",
    "As such, we can train a logistic regression model which takes the angles formed between the intersecting vectors and outputs whether the finger is raised or not !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting training labels\n",
    "\n",
    "First of all, we'll get training data for our logistic regression algorithm. How will we find the data ? We'll create our own ! We can create our own data using a very simple and efficient python script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating a MultiProcessing python script to get training data\n",
    "\n",
    "We'll create a script that launches two processes to do the following :\n",
    "\n",
    "Process 1 : Keep the camera open and detecting all of our hands landmarks\n",
    "\n",
    "Process 2 : Awaits user input (1 or 0 standing for raised or not raised)\n",
    "\n",
    "When user input is set, process one will start saving the landmark data of each frame it captures. It'll then calculate the angles between landmark vectors and save the angles corresponding to one finger into an list, appending to the list the label. Finally, it'll save the list entries into a CSV file. After that, it'll wait for the user to input a new label to repeat the process again.\n",
    "\n",
    "Since Jupyter notebooks don't support multiprocessing very well, we've saved all the needed code for this section in a Module called MultiProcessLabelingModule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the module\n",
    "import MultiProcessLabelingModule as mplm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll call the startLabelingProcess() twice, once to label training data for our thumb since it raises a little different than the other fingers, and once to label training data for the rest of our fingers. Since the rest of our fingers all behave in a similar way, we can just get training data on one of them and apply the model predictions to all the others. I'll choose the index finger as it's easier to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do NOT enter input before your camera starts\n",
    "#Do NOT interrupt the process while running, if you want it to end then enter a label other than 0 or 1\n",
    "mplm.startLabelingProcess(4) #Thumb training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do NOT enter input before your camera starts\n",
    "#Do NOT interrupt the process while running, if you want it to end then enter a label other than 0 or 1\n",
    "mplm.startLabelingProcess(8) #Index (and rest of fingers) training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load our datasets !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataThumb = pd.read_csv(\"trainingDatathumb.csv\")\n",
    "Xthumb = dataThumb.iloc[:, :-1].values\n",
    "Ythumb = dataThumb.iloc[:, -1].values\n",
    "\n",
    "dataIndex = pd.read_csv(\"trainingDataindex.csv\")\n",
    "Xindex = dataIndex.iloc[:, :-1].values\n",
    "Yindex = dataIndex.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define and train and our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelThumb = LogisticRegression()\n",
    "modelThumb.fit(Xthumb, Ythumb)\n",
    "with open(\"modelThumb.pkl\", \"wb\") as f:\n",
    "    pickle.dump(modelThumb, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelIndex = LogisticRegression()\n",
    "modelIndex.fit(Xindex, Yindex)\n",
    "with open(\"modelIndex.pkl\", \"wb\") as f:\n",
    "    pickle.dump(modelIndex, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now define a helper function which takes a landmark list and outputs a numpy array of angles for the specified finger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnAngleArray(lmList, tip, hand):\n",
    "    landmarksList = [lmList[hand][tip][1:4], lmList[hand][tip-1][1:4], lmList[hand][tip-2][1:4], lmList[hand][tip-3][1:4], lmList[hand][0][1:4]] #We'll get data from only one hand at a time\n",
    "    angles = []\n",
    "    for point in range(1,4):\n",
    "        angles.append(mplm.angle_between_vectors(mplm.construct_vector(np.array(landmarksList[point]), np.array(landmarksList[point-1])),\n",
    "                                                mplm.construct_vector(np.array(landmarksList[point]), np.array(landmarksList[point+1]))))\n",
    "    return np.array(angles)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll define our advanced counting raised fingers algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def advancedCountFingers(lmList): #Takes landmarks list and outputs the number of fingers raised\n",
    "    tipIds = [4, 8, 12, 16, 20]\n",
    "    fingersRaised = 0\n",
    "    if(len(lmList) > 0):\n",
    "        for hand in range(len(lmList)):\n",
    "            for tip in tipIds:\n",
    "                angles = returnAngleArray(lmList, tip, hand)\n",
    "                angles = angles.reshape(1, -1)\n",
    "                if(tip == 4): #Special logic for Thumb\n",
    "                    prediction = modelThumb.predict(angles)\n",
    "                    fingersRaised += 1 if prediction>=0.5 else 0\n",
    "                else:\n",
    "                    prediction = modelIndex.predict(angles)\n",
    "                    fingersRaised += 1 if prediction >= 0.5 else 0\n",
    "            \n",
    "    return fingersRaised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Let's try out our model !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "captureAndDetect(advancedCountFingers) #Interrupt whenever you want"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model works amazingly well ! It's detecting the fingers raised near perfectly as long as mediapipe itself is tracking and labeling the landmarks well ! Moreover since it's a simple logistic regression model, it isn't computationally expensive and we get decent framerates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try out our math game !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1/10 : 30 / 6 = 5\n",
      "Question 2/10 : 8 / 2 = 4\n",
      "Question 3/10 : 12 / 2 = 6\n",
      "Question 4/10 : 21 / 3 = 7\n",
      "Question 5/10 : 27 / 9 = 3\n",
      "Question 6/10 : 14 / 7 = 2\n",
      "Question 7/10 : 18 / 3 = 6\n",
      "Question 8/10 : 2 / 2 = 1\n",
      "Question 9/10 : 28 / 4 = 7\n",
      "Question 10/10 : 8 / 8 = 1\n"
     ]
    }
   ],
   "source": [
    "computerVisionMath(advancedCountFingers, 10) #Interrupt whenever you want"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works perfectly !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
